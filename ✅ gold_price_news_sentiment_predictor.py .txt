#!/usr/bin/env python3
"""
Gold Price Prediction with News Sentiment Analysis and Technical Indicators
Author: Mohammed Haider Hussain
"""

import os
import sys
import logging
import argparse
from datetime import datetime

import requests
import joblib
import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns
import nltk

from nltk.sentiment.vader import SentimentIntensityAnalyzer
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
import lightgbm as lgb
import ta  # Technical Analysis indicators

# ——— CONFIG ——— #
NEWS_API_KEY = "4d65f86475074aed8bd21bfb63acc76d"
START_DATE = "2018-01-01"
END_DATE = datetime.today().strftime("%Y-%m-%d")
TICKER = "GC=F"  # Gold Futures
MODEL_PATH = "gold_price_model.joblib"
PRED_PATH = "predictions.csv"
PLOT_PATH = "actual_vs_predicted.png"

# ——— SETUP ——— #
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger()
nltk.download("vader_lexicon", quiet=True)
sia = SentimentIntensityAnalyzer()

# ——— FUNCTIONS ——— #

def fetch_gold_data():
    logger.info("Downloading gold price data...")
    df = yf.download(TICKER, start=START_DATE, end=END_DATE)[["Adj Close", "Volume"]]
    df.columns = ["adj_close", "volume"]
    df["return"] = df["adj_close"].pct_change()
    return df.dropna()

def fetch_news_data():
    logger.info("Fetching news headlines from NewsAPI...")
    articles, page = [], 1
    while True:
        url = "https://newsapi.org/v2/everything"
        params = {
            "q": "gold price",
            "from": START_DATE,
            "to": END_DATE,
            "language": "en",
            "pageSize": 100,
            "page": page,
            "apiKey": NEWS_API_KEY
        }
        r = requests.get(url, params=params)
        data = r.json()
        if data.get("status") != "ok" or not data.get("articles"):
            break
        articles += data["articles"]
        if len(data["articles"]) < 100:
            break
        page += 1
    news_df = pd.DataFrame(articles)
    news_df["date"] = pd.to_datetime(news_df["publishedAt"]).dt.date
    return news_df[["date", "title"]].rename(columns={"title": "headline"})

def compute_sentiment(news_df):
    logger.info("Calculating daily sentiment scores...")
    news_df["sentiment"] = news_df["headline"].apply(lambda x: sia.polarity_scores(x)["compound"])
    return news_df.groupby("date")["sentiment"].mean()

def add_indicators(df):
    logger.info("Adding technical indicators...")
    df["sma10"] = ta.trend.SMAIndicator(df["adj_close"], window=10).sma_indicator()
    df["rsi14"] = ta.momentum.RSIIndicator(df["adj_close"], window=14).rsi()
    macd = ta.trend.MACD(df["adj_close"])
    df["macd"] = macd.macd()
    df["macd_signal"] = macd.macd_signal()
    return df

def create_features(df, sentiment):
    logger.info("Merging sentiment and creating lag features...")
    df = df.join(sentiment, how="left").fillna(0)
    df = add_indicators(df)
    for lag in [1, 2, 3]:
        df[f"return_lag{lag}"] = df["return"].shift(lag)
        df[f"sentiment_lag{lag}"] = df["sentiment"].shift(lag)
    return df.dropna()

def train_model(df, model_choice="xgb"):
    logger.info("Training model with TimeSeriesSplit...")
    features = [col for col in df.columns if "lag" in col] + ["sma10", "rsi14", "macd", "macd_signal", "volume"]
    X, y = df[features], df["adj_close"]

    tss = TimeSeriesSplit(n_splits=5)
    if model_choice == "lgb":
        model = lgb.LGBMRegressor()
        params = {"n_estimators": [100, 200], "learning_rate": [0.01, 0.1]}
    else:
        model = XGBRegressor()
        params = {"n_estimators": [100, 200], "learning_rate": [0.01, 0.1], "max_depth": [3, 5]}

    gs = GridSearchCV(model, params, cv=tss, scoring="neg_root_mean_squared_error", n_jobs=-1)
    gs.fit(X, y)

    best_model = gs.best_estimator_
    logger.info(f"Best params: {gs.best_params_}")

    train_idx, test_idx = list(tss.split(X))[-1]
    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]
    preds = best_model.predict(X_test)

    rmse = mean_squared_error(y_test, preds, squared=False)
    r2 = r2_score(y_test, preds)

    logger.info(f"Test RMSE: {rmse:.2f} | R²: {r2:.2f}")
    joblib.dump(best_model, MODEL_PATH)
    logger.info(f"Model saved: {MODEL_PATH}")

    result = pd.DataFrame({
        "date": X_test.index,
        "actual": y_test,
        "predicted": preds
    })
    result.to_csv(PRED_PATH, index=False)
    logger.info(f"Predictions saved: {PRED_PATH}")

    plt.figure(figsize=(10, 5))
    sns.lineplot(x="date", y="value", hue="variable",
                 data=pd.melt(result, id_vars=["date"]))
    plt.title("Gold Price: Actual vs Predicted")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(PLOT_PATH)
    plt.show()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", choices=["xgb", "lgb"], default="xgb", help="Choose model type")
    args = parser.parse_args()

    gold_data = fetch_gold_data()
    news_data = fetch_news_data()
    sentiment = compute_sentiment(news_data)
    full_df = create_features(gold_data, sentiment)
    train_model(full_df, model_choice=args.model)

if __name__ == "__main__":
    main()
